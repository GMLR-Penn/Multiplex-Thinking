import numpy as np
from typing import Dict, List, Any, Callable

MYPROMPT_ORIG = [
"",
"",
"""

{question}

Choose the better answer from the following two responses:
Solution 1: {answer1}

Solution 2: {answer2}

""",
"""Let's analyze this step by step and decide which solution is better, and then answer \\boxed{Solution 1} or \\boxed{Solution 2}.
""",
]

MYPROMPT0 = [
"",
"Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. "
"You should choose the assistant that follows the user's instructions and answers the user's question better. "
"Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their responses. If the instruction contains harmful content, prioritize the harmlessness and safety of the response."
"Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. "
"Do not allow the length of the refponses to influence your evaluation. Do not favor certain names of the assistants. "
"Be as objective as possible. ",
"""

{question}

Choose the better answer from the following two responses:
Solution 1: {answer1}

Solution 2: {answer2}

""",
"""Let's analyze this step by step and decide which solution is better, and then answer \\boxed{Solution 1} or \\boxed{Solution 2}.
""",
]

MYPROMPT1 = [
"Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. "
"You should choose the assistant that follows the user's instructions and answers the user's question better. "
"Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their responses. If the instruction contains harmful content, prioritize the harmlessness and safety of the response."
"Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. "
"Do not allow the length of the refponses to influence your evaluation. Do not favor certain names of the assistants. "
"Be as objective as possible. "
"Your output should only consist of '\\boxed{Assistant 1}' if assistant 1 is better, or '\\boxed{Assistant 2}' if assistant 2 is better. Omit any other output.\n",
"",
"""
## Query

{question}

## Assistant responses

### Assistant 1

{answer1}

### Assistant 2

{answer2}

""",
"""

## Analysis

Let's analyze this step by step and decide which assistant is better, and then answer \\boxed{Assistant 1} or \\boxed{Assistant 2}.
""",
]


MYPROMPT2 = [
"""
You are a helpful assistant in evaluating the quality of the responses for a given instruction. Your goal is to select the best response for the given instruction.
Select Assistant 1 or Assistant 2, that is better for the given instruction. The two responses are generated by two different AI assistants respectively.
Do NOT say both / neither are good.

Here are some rules of the evaluation:
(1) If the instruction does not contain harmful content, you should prioritize evaluating whether the output honestly/precisely/closely executes the instruction, then consider its helpfulness, accuracy, level of detail, harmlessness, etc.
(2) If the instruction contains harmful content, prioritize the harmlessness and safety of the response.
(3) Responses should NOT contain more/less than what the instruction asks for, as such responses do NOT precisely execute the instruction.
(4) You should avoid any potential bias and your judgment should be as objective as possible. Here are some potential sources of bias:
- The order in which the responses were presented should NOT affect your judgment, as Response A and Response B are **equally likely** to be the better.
- The length of the responses should NOT affect your judgement, as a longer response does not necessarily correspond to a better response. When making your decision, evaluate if the response length is appropriate for the given instruction.
(5) Your output should only consist of '\\boxed{Assistant 1}' if assistant 1 is better, or '\\boxed{Assistant 2}' if assistant 2 is better. Omit any other output.
""",
"",
"""
## Query

{question}

## Assistant responses

### Assistant 1

{answer1}


### Assistant 2

{answer2}

""",
"""

## Analysis

Let's analyze this step by step and decide which assistant is better, and then answer \\boxed{Assistant 1} or \\boxed{Assistant 2}.
""",
]

MYPROMPT21 = [
"",
"",
"""
## Query

{question}

## Assistant responses

### Assistant 1

{answer1}


### Assistant 2

{answer2}

""",
"""

## Analysis

Let's analyze this step by step and decide which assistant is better, and then answer \\boxed{Assistant 1} or \\boxed{Assistant 2}.
""",
]


MYPROMPT3 = [
"",
"""
## Instructions

Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. "
"You should choose the assistant that follows the user's instructions and answers the user's question better. You should choose the assistant that follows the user's instructions and answers the user's question better. Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. Do not allow the length of the refponses to influence your evaluation. Do not favor certain names of the assistants. Be as objective as possible. Your output should only consist of '\\boxed{Assistant 1}' if assistant 1 is better, or '\\boxed{Assistant 2}' if assistant 2 is better. Omit any other output.
""",
"""

## Query

{question}

## Assistant responses

### Assistant 1

{answer1}

---------------------------------------------------

### Assistant 2

{answer2}

---------------------------------------------------

""",
"""

## Analysis

Let's analyze this step by step and decide which assistant is better, and then answer \\boxed{Assistant 1} or \\boxed{Assistant 2}.
""",
]


MYPROMPT4 = [
"",
"Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. "
"You should choose the assistant that follows the user's instructions and answers the user's question better. "
"Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their responses. If the instruction contains harmful content, prioritize the harmlessness and safety of the response."
"Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. "
"Do not allow the length of the refponses to influence your evaluation. Do not favor certain names of the assistants. "
"Be as objective as possible. "
"Your output should only consist of '\\boxed{Solution 1}' or '\\boxed{Solution 2}'. Omit any other output.",
"""

Query:
{question}

Choose the better answer from the following two responses:

Solution 1: {answer1}

----------------------------------------------------

Solution 2: {answer2}

----------------------------------------------------

""",
"",
]

MYPROMPT5 = [
"",
"Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. "
"You should choose the assistant that follows the user's instructions and answers the user's question better. "
"Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their responses. If the instruction contains harmful content, prioritize the harmlessness and safety of the response."
"Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. "
"Do not allow the length of the refponses to influence your evaluation. Do not favor certain names of the assistants. "
"Be as objective as possible. "
"Your output should only consist of '\\boxed{Solution 1}' or '\\boxed{Solution 2}'. Omit any other output.",
"""

Query:
{question}

Choose the better answer from the following two responses:

Solution 1: {answer1}

----------------------------------------------------

Solution 2: {answer2}

----------------------------------------------------

""",
"Let's think very hard and check each solution carefully step by step, and then answer \\boxed{Solution 1} or \\boxed{Solution 2}.",
]


def get_online_transform_func(template_name: str, data_source_apply_template: str="skywork_raw_v2", shuffle_response_order: bool=True, random_seed: int=42) -> Callable:
  rand = np.random.RandomState(random_seed)
  
  if template_name == 'my_prompt0':
      prompt_template = MYPROMPT0
  elif template_name == 'my_prompt1':
      prompt_template = MYPROMPT1
  elif template_name == 'my_prompt2':
      prompt_template = MYPROMPT2
  elif template_name == 'my_prompt3':
      prompt_template = MYPROMPT3
  elif template_name == 'my_prompt4':
      prompt_template = MYPROMPT4
  elif template_name == 'my_prompt5':
      prompt_template = MYPROMPT5
  elif template_name == 'my_prompt21':
      prompt_template = MYPROMPT21
  else:
      prompt_template = MYPROMPT_ORIG
  
  system_prompt = prompt_template[0]

  def _transform(example: Dict[str, Any]) -> Dict[str, Any]:
    if data_source_apply_template == "_all" or example["data_source"] == data_source_apply_template:
      question = example["question"]
      response1 = example["response1"]
      response2 = example["response2"]
      answer = example["answer"]
      extra_info = example["extra_info"]
      if shuffle_response_order:
        if rand.rand() < 0.5:
          response1, response2 = response2, response1
          answer = "2" if answer == "1" else "1"
      
      problem = prompt_template[2].format(question=question, answer1=response1, answer2=response2)
      user_content = prompt_template[1] + problem + prompt_template[3]
      new_example = {
        "data_source": example["data_source"],
        "prompt": [{
            "role": "user",
            "content": user_content,},
            {
            "role": "system",
            "content": system_prompt
        }],
        "ability": "general",
        "reward_model": {
            "style": "rule",
            "ground_truth": answer
        },
        "extra_info": extra_info,
      }
    #   print(new_example)
      # if extra_info.get("index") is not None and extra_info["index"] <= 2:
      #   print(f"new_example: {new_example}")
      return new_example
          
    else:
      new_example = {
        "data_source": example["data_source"],
        "prompt": example["prompt"],
        "ability": example["ability"],
        "reward_model": example["reward_model"],
        "extra_info": example["extra_info"],
      }
      return new_example
  
  return _transform
  